input {
  udp {
    port => 514
    codec => "json"
  }
}

filter {
  if [source] == "filterlog" {
    # First, unescape the JSON string in the log field
    mutate {
      gsub => [
        # Remove newline characters and surrounding quotes
        "log", "\\n", "",
        "log", "\\\"", "\""
      ]
    }

    # Then, parse the unescaped JSON string
    json {
      source => "log"
      target => "parsed_log"
    }
    
    mutate {
      add_field => {
        "log_timestamp" => "%{[parsed_log][log_timestamp]}"
        "process_name" => "%{[parsed_log][process_name]}"
        "process_id" => "%{[parsed_log][process_id]}"
        "action" => "%{[parsed_log][action]}"
        "src_ip" => "%{[parsed_log][src_ip]}"
        "dst_ip" => "%{[parsed_log][dst_ip]}"
        "src_port" => "%{[parsed_log][src_port]}"
        "dst_port" => "%{[parsed_log][dst_port]}"
        "network_interface" => "%{[parsed_log][network_interface]}"
        "direction" => "%{[parsed_log][direction]}"
        "protocol" => "%{[parsed_log][protocol]}"
      }
      remove_field => ["log", "parsed_log"]
    }

    date {
      match => [ "log_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
      timezone => "Asia/Jakarta"  # Adjust this to the correct timezone
      target => "@timestamp"
    }
  }

  if [source] == "suricata" {
    json {
      source => "log"
      target => "parsed_log"
    }

    mutate {
      add_field => {
        "timestamp" => "%{[parsed_log][timestamp]}"
        "flow_id" => "%{[parsed_log][flow_id]}"
        "in_iface" => "%{[parsed_log][in_iface]}"
        "event_type" => "%{[parsed_log][event_type]}"
        "src_ip" => "%{[parsed_log][src_ip]}"
        "src_port" => "%{[parsed_log][src_port]}"
        "dest_ip" => "%{[parsed_log][dest_ip]}"
        "dest_port" => "%{[parsed_log][dest_port]}"
        "proto" => "%{[parsed_log][proto]}"
        "pkt_src" => "%{[parsed_log][pkt_src]}"
        "src_mac" => "%{[parsed_log][ether][src_mac]}"
        "dest_mac" => "%{[parsed_log][ether][dest_mac]}"
        "http_hostname" => "%{[parsed_log][http][hostname]}"
        "http_port" => "%{[parsed_log][http][http_port]}"
        "http_url" => "%{[parsed_log][http][url]}"
        "http_user_agent" => "%{[parsed_log][http][http_user_agent]}"
        "http_content_type" => "%{[parsed_log][http][http_content_type]}"
        "http_method" => "%{[parsed_log][http][http_method]}"
        "http_protocol" => "%{[parsed_log][http][protocol]}"
        "http_status" => "%{[parsed_log][http][status]}"
        "http_length" => "%{[parsed_log][http][length]}"
        "app_proto" => "%{[parsed_log][app_proto]}"
        "filename" => "%{[parsed_log][fileinfo][filename]}"
        "file_gaps" => "%{[parsed_log][fileinfo][gaps]}"
        "file_state" => "%{[parsed_log][fileinfo][state]}"
        "file_stored" => "%{[parsed_log][fileinfo][stored]}"
        "file_size" => "%{[parsed_log][fileinfo][size]}"
        "file_tx_id" => "%{[parsed_log][fileinfo][tx_id]}"
      }
      remove_field => ["log", "parsed_log"]
    }

    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    manage_template => false
    index => "logs-%{+YYYY.MM.dd}"
  }

  stdout { codec => rubydebug }
}
